{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "60000\n",
      "10000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(training_images))\n",
    "print(len(training_labels))\n",
    "print(len(test_images))\n",
    "print(len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images = training_images.reshape(60000, 28, 28,1)\n",
    "training_images = training_images / 255.0\n",
    "test_images = test_images.reshape(10000, 28, 28, 1)\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if (logs.get('accuracy') > 0.99):\n",
    "      print(\"\\nReached 99% accuracy so cancelling training\")\n",
    "      self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = myCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - 64 Convolutions | 1 Convolutional layer | 1 pooling layer | 100 epochs | callback for 99% accuracy\n",
      "------------------------\n",
      "Train on 60000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 35s 577us/sample - loss: 0.3724 - accuracy: 0.8677\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 34s 565us/sample - loss: 0.2524 - accuracy: 0.9079\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 34s 568us/sample - loss: 0.2072 - accuracy: 0.9236\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 34s 574us/sample - loss: 0.1717 - accuracy: 0.9368\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 34s 570us/sample - loss: 0.1461 - accuracy: 0.9460\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 34s 569us/sample - loss: 0.1194 - accuracy: 0.9549\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 34s 571us/sample - loss: 0.1007 - accuracy: 0.9632\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 34s 569us/sample - loss: 0.0828 - accuracy: 0.9694\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 34s 568us/sample - loss: 0.0686 - accuracy: 0.9747\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 34s 568us/sample - loss: 0.0570 - accuracy: 0.9793\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 35s 578us/sample - loss: 0.0505 - accuracy: 0.9823\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 34s 563us/sample - loss: 0.0414 - accuracy: 0.9856\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 34s 571us/sample - loss: 0.0366 - accuracy: 0.9871\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 34s 563us/sample - loss: 0.0306 - accuracy: 0.9892\n",
      "Epoch 15/100\n",
      "59968/60000 [============================>.] - ETA: 0s - loss: 0.0285 - accuracy: 0.9900\n",
      "Reached 99% accuracy so cancelling training\n",
      "60000/60000 [==============================] - 34s 562us/sample - loss: 0.0285 - accuracy: 0.9900\n",
      "10000/10000 [==============================] - 1s 136us/sample - loss: 0.4714 - accuracy: 0.9067\n"
     ]
    }
   ],
   "source": [
    "print(\"Model - 64 Convolutions | 1 Convolutional layer | 1 pooling layer | 100 epochs | callback for 99% accuracy\")\n",
    "print(\"------------------------\")\n",
    "model = tf.keras.Sequential([\n",
    "                              tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28,28,1)),\n",
    "                              tf.keras.layers.MaxPooling2D(2,2),\n",
    "                              tf.keras.layers.Flatten(),\n",
    "                              tf.keras.layers.Dense(128, activation='relu'),\n",
    "                              tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(training_images, training_labels, epochs=100, callbacks=[callback])\n",
    "test_loss = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - 32 Convolutions | 1 Convolutional layer | 1 pooling layer | 100 epochs | callback for 99% accuracy\n",
      "------------------------\n",
      "Train on 60000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 17s 289us/sample - loss: 0.3863 - accuracy: 0.8633\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 17s 289us/sample - loss: 0.2621 - accuracy: 0.9053\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 17s 287us/sample - loss: 0.2180 - accuracy: 0.9198\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 17s 286us/sample - loss: 0.1849 - accuracy: 0.9318\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 17s 285us/sample - loss: 0.1588 - accuracy: 0.9409\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 17s 285us/sample - loss: 0.1362 - accuracy: 0.9494\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 17s 285us/sample - loss: 0.1140 - accuracy: 0.9579\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 17s 286us/sample - loss: 0.0963 - accuracy: 0.9653\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 17s 285us/sample - loss: 0.0828 - accuracy: 0.9695\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 17s 285us/sample - loss: 0.0708 - accuracy: 0.9743\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 17s 286us/sample - loss: 0.0587 - accuracy: 0.9794\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 17s 287us/sample - loss: 0.0519 - accuracy: 0.9811\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 17s 290us/sample - loss: 0.0428 - accuracy: 0.9844\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 17s 287us/sample - loss: 0.0375 - accuracy: 0.9866\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 17s 290us/sample - loss: 0.0340 - accuracy: 0.9877\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 17s 287us/sample - loss: 0.0309 - accuracy: 0.9895\n",
      "Epoch 17/100\n",
      "59840/60000 [============================>.] - ETA: 0s - loss: 0.0266 - accuracy: 0.9905\n",
      "Reached 99% accuracy so cancelling training\n",
      "60000/60000 [==============================] - 17s 289us/sample - loss: 0.0266 - accuracy: 0.9905\n",
      "10000/10000 [==============================] - 1s 78us/sample - loss: 0.4821 - accuracy: 0.9136\n"
     ]
    }
   ],
   "source": [
    "print(\"Model - 32 Convolutions | 1 Convolutional layer | 1 pooling layer | 100 epochs | callback for 99% accuracy\")\n",
    "print(\"------------------------\")\n",
    "model2 = tf.keras.Sequential([\n",
    "                              tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),\n",
    "                              tf.keras.layers.MaxPooling2D(2,2),\n",
    "                              tf.keras.layers.Flatten(),\n",
    "                              tf.keras.layers.Dense(128, activation='relu'),\n",
    "                              tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model2.fit(training_images, training_labels, epochs=100, callbacks=[callback])\n",
    "test_loss2 = model2.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
